# ACM CCS 近五年接收论文列表

## CCS 2018

*CCS 2018共收到809篇论文，录取134篇论文，录取率为16.6%*

**相关论文列表:**


1. Model-Reuse Attacks on Learning Systems
1. Property Inference Attacks on Deep Neural Networks using Permutation Invariant Representations
1. Machine Learning with Membership Privacy using Adversarial Regularization


## CCS 2017

*CCS 2017共收到836篇论文，录取151篇论文，录取率为18%*

**相关论文列表:**

1. MagNet: a Two-Pronged Defense against Adversarial Examples
1. Machine Learning Models that Remember Too Much
1. Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning 
1. Practical Secure Aggregation for Privacy-Preserving Machine Learning
1. Use Privacy in Data-Driven Systems: Theory and Experiments with Machine Learnt Programs
1. Practical Attacks Against Graph-based Clustering


## CCS 2016

**相关论文列表:**

1. Accessorize to a Crime: Real and Stealthy Attacks on State-Of-The-Art Face Recognition
2. Deep Learning with Differential Privacy


## CCS 2015

**相关论文列表**

1. Face/Off: Preventing Privacy Leakage From Photos in Social Networks
1. Inference Attacks on Property-Preserving Encrypted Databases
1. Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures
1. Privacy-Preserving Deep Learning


## CCS 2014

**相关论文列表**

*没找到很相关的论文...*

# IEEE S&P 近五年接收论文

## S&P 2018

**相关论文列表**
1. AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation 
1. Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning
1. Stealing Hyperparameters in Machine Learning


## S&P 2017

**相关论文列表**

1. Membership Inference Attacks against Machine Learning Models
1. SecureML: A System for Scalable Privacy-Preserving Machine Learning
1. Towards Evaluating the Robustness of Neural Networks 


## S&P 2016

**相关论文列表**

1. Algorithmic Transparency via Quantitative Input Influence: Theory and Experiments with Learning Systems 
1. Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks 


## S&P 2015

**相关论文列表**

1. Towards Making Systems Forget with Machine Unlearning


## S&P 2014

**相关论文列表**

1. Practical Evasion of a Learning-Based Classifier: A Case Study 