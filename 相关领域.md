## 相关领域

> 1.Attacks on statistical and machine learning models
* Hacking smart machines with smarter ones: How to extract meaningful data from machine learning classifiers
    * 已知 SVM 和 HMM 模型的参数，来推断训练集中的某些信息

> 2.Model inversion

1. Model inversion attacks thatexploit confidence information and basic countermeasures
2. Privacy in pharmacogenetics: An end-to-end case study of personalized Warfarin dosing 
    * 运用在人脸识别算法中，可以推断出当前class的输入(是所有符合这个class的训练数据feature的平均值)
    * 可以根据模型的输出来推断出模型输入的一些特征
3. https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md 
    * 解释了 model inversion 为什么能够成功
    * 为什么 model inversion 不会造成隐私泄露

> 3.Model extraction
* Stealing machine learning models via prediction APIs
    * 提取出目标模型参数，重建一个和目标模型类似的模型

> 4.Privacy-preserving machine learning

主要是需要避免学习算法在学习过程中直接接触到训练数据。  
* 多方计算被应用了很多
    * **decision trees**
        * Privacy preserving data mining
    * **linear regression**
        * Privacy-preserving multivariate statistical analysis: Linear regression and classification
    * **naive bayes**
        * Privacy-preserving Naive Bayes classification
    * **k-means clustering**
        * Privacy-preserving distributed k-means clustering over arbitrarily partitioned data
* 差分隐私
    * **Differential privacy**
        * Differential privacy
    * **linear regression and logistic regression**
        * Privacy-preserving logistic regression
        * Functional mechanism: Regression analysis under differential privacy,
    * **support vector machine**
        * Learning in a large function space: Privacy-preserving mechanisms for SVM learning
    * **risk minimization** 
        * Private empirical risk minimization: Efficient algorithms and tight error bounds
        * Differentially private empirical risk minimization
        * Privacy aware learning
    * **deep learning**
        * Deep learning with differential privacy
        * Privacy-preserving deep learning