# 机器学习安全和隐私保护
1. 安全
    * 机器学习常见的安全威胁
        * 投毒攻击
        * 对抗攻击
        * 询问攻击
    * 机器学习安全威胁的防御方法
        * 正则化
        * 对抗训练
        * 防御精馏
2. 隐私
    * 机器学习常见的隐私威胁
        * 训练数据窃取
        * 逆向攻击
        * 成员推理攻击
    * 机器学习隐私保护技术
        * 同态加密
        * 差分隐私


* 保障机器学习的安全(安全性、可用性)
* 保障用户的隐私(机密性)

1. 安全：保障用户数据被正确的使用，保障机器学习的可用性和完整性。
2. 隐私：人们有权利决定自己的私有数据不被公开。


**机器学习中常见的安全威胁**
1. 训练阶段
    * 投毒攻击
        * 敌手对训练数据进行修改、删除或者注入精心制作的恶意数据，从而改变原始训练数据的分布，从而改变了训练得到的模型，这样在进行预测时，该模型对测试数据的预测就会存在偏差。
        * 可以修改训练数据的标签 `y`
        * 插入精心制作的恶意样本
        * 如果一开始训练数据就是确定好的，那么敌手比较难以修改训练数据；但是如果训练过程中是不断添加训练数据，那么这种情况下敌手就有可乘之机。
2. 预测阶段
    * 对抗攻击
        * **白盒，知晓模型结构和各种参数**
        * 主要是搜索对抗样本，是一个优化问题
        * 搜索一个最小也最优的扰动`r`
        * *针对目标攻击*：将样本错误分类到一个指定类别中；
        * *非针对目标攻击*：只要求将对抗样本错误分类，不管其被错误分类到哪个类别。
    * 询问攻击
        * **完全黑盒**，只能利用预测API的结果
        

**机器学习安全威胁的防御策略**
1. 正则化
    * 加入正则项，提升模型的泛化能力
    * 在对未知样本的预测时，鲁棒性更好
2. 对抗训练
    * 在训练集中加入对抗样本，增加训练得到的模型的鲁棒性
    * *对抗样本具有多样性，在训练集中添加所有的对抗样本是不现实的*
3. 防御精馏
    * 产生的模型决策边界更加平滑，对扰动不敏感，模型更加鲁棒
    * 也可以直接检测输入的样本是否是对抗样本：如果发现是，那么直接拒绝这个请求


**机器学习中常见的隐私威胁**
1. 训练阶段
    * 数据窃取
        1. 集中式训练
            * 将各方的用户数据收集到一块进行训练
        2. 联合分布训练 
            * 各个用户利用自己的数据单独训练模型
            * 不同的用户之间共享模型的参数
2. 预测阶段
    * 提取训练数据信息
        * 重建训练集中的图像数据
        * *成员推理攻击*：判断一条记录是否在训练集中
    * 提取目标模型信息
        * 根据输入-输出对，来训练一个辅助模型，模拟目标模型


**机器学习隐私保护技术**
1. 同态加密
    * 在预测阶段首先将样本进行加密，机器学习模型可以对密文进行预测，再将得到的结果解密
    * 一般很少在训练过程中使用同态加密，这样使得计算开销更大了
    * 一般在预测阶段使用
2. 差分隐私
    * 在原始数据中加入一部分微小的噪声，改变原始数据，使得对于单个样本的分析是没有意义的，但是数据总体仍然保持着莫衷统计特性
    * 目标：*在隐私保护和目标模型的准确度之间做平衡*



**待阅读论文列表**
1. Intriguing properties of neural networks
    * 对图片添加轻微的扰动，可以欺骗神经网络，这个过程就是*对抗攻击*。敌手精心制作的错分类样本就是*对抗样本*。
2. Practical black-box attacks against machine learning
    * 利用敌手产生的合成输入训练一个替代模型，利用替代模型制作对抗样本，这些对抗样本可以被原本的目标模型错误分类。

3. Machine Learning Models that Remembers Too Much
    * 机器学习算法在训练过程中，可能会记住训练的数据。提出了在不影响预测准确率的情况下，能够提取出训练数据的子集。


4. Model inversion attacks that exploit confidence information and basic countermeasures
    * 通过观察目标模型的预测结果，反过来重建模型输入的人脸图像数据

5. 


